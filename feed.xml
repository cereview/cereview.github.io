<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-01-24T19:17:45+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">amitabh yadav</title><subtitle>It&apos;s not right but the thing is, it&apos;s not even wrong!</subtitle><author><name>Amitabh Yadav</name></author><entry><title type="html">Myths and Legends in High Performance Computing</title><link href="http://localhost:4000/posts/2023/myths-and-legends-hpc/" rel="alternate" type="text/html" title="Myths and Legends in High Performance Computing" /><published>2023-01-24T00:00:00+01:00</published><updated>2023-01-24T00:00:00+01:00</updated><id>http://localhost:4000/posts/2023/myths-and-legends-hpc</id><content type="html" xml:base="http://localhost:4000/posts/2023/myths-and-legends-hpc/"><![CDATA[<h2 id="number-representation">Number Representation</h2>

<p>Conventional and oftentimes exotic methods of number representation can lead to performance gains in terms of simpler and faster circuits. While conventional methods are used extensively, the unconventional ones find application in special purpose digital circuits and systems.</p>

<blockquote>
  <p>Computer arithmetic deals with the hardware realization of arithmetic functions to support various computer architectures as well as with arithmetic algorithms for firmware or software implementation.</p>
</blockquote>

<p>A major thrust of digital computer arithmetic is the design of hardware algorithms and circuits to enhance the speed of numeric operations. Thus computer arithmetic complements the architectural and algorithmic speedup techniques for high-performance computer architecture design and parallel processing.</p>

<p>Objectives:</p>

<ul>
  <li>To be able to describe the core design elements of the Arithmetic and Logic Unit (ALUs) of top-of-the-line CPUs designed using high-performance parallel arithmetic circuits.</li>
  <li>At times we will also deal with slow bit-serial designs for embedded applications, where implementation cost and input/output pin limitations are of prime concern.</li>
  <li>It would be a mistake, though, to conclude that computer arithmetic is useful only to computer designers. We will see shortly that you can use scientific calculations more effectively and write programs that are more accurate and/or more efficient after a study of computer arithmetic.</li>
  <li>You will be able to render informed judgment when faced with the problem of choosing a digital signal processor chip for your project.</li>
</ul>

<h3 id="fixed-point-numbers">Fixed Point Numbers</h3>

<p><img src="/images/computer-arithmetic/scope-of-computer-arithmetic.png" alt="The scope of computer arithmetic" /></p>

<h3 id="references">References:</h3>

<ol>
  <li>Behrooz Parhami, <em>Computer Arithmetic: Algorithms and Hardware Designs</em>, 2nd Edition, Oxford University Press, New York, 2010.</li>
  <li>Henry S. Warren, Jr. , <em>Hacker’s Delight</em>, 2nd Edition, Addison-Wesley Professional, September 2012.</li>
</ol>]]></content><author><name>Amitabh Yadav</name></author><category term="Computing Reviews" /><summary type="html"><![CDATA[Number Representation Conventional and oftentimes exotic methods of number representation can lead to performance gains in terms of simpler and faster circuits. While conventional methods are used extensively, the unconventional ones find application in special purpose digital circuits and systems. Computer arithmetic deals with the hardware realization of arithmetic functions to support various computer architectures as well as with arithmetic algorithms for firmware or software implementation. A major thrust of digital computer arithmetic is the design of hardware algorithms and circuits to enhance the speed of numeric operations. Thus computer arithmetic complements the architectural and algorithmic speedup techniques for high-performance computer architecture design and parallel processing. Objectives: To be able to describe the core design elements of the Arithmetic and Logic Unit (ALUs) of top-of-the-line CPUs designed using high-performance parallel arithmetic circuits. At times we will also deal with slow bit-serial designs for embedded applications, where implementation cost and input/output pin limitations are of prime concern. It would be a mistake, though, to conclude that computer arithmetic is useful only to computer designers. We will see shortly that you can use scientific calculations more effectively and write programs that are more accurate and/or more efficient after a study of computer arithmetic. You will be able to render informed judgment when faced with the problem of choosing a digital signal processor chip for your project. Fixed Point Numbers References: Behrooz Parhami, Computer Arithmetic: Algorithms and Hardware Designs, 2nd Edition, Oxford University Press, New York, 2010. Henry S. Warren, Jr. , Hacker’s Delight, 2nd Edition, Addison-Wesley Professional, September 2012.]]></summary></entry><entry><title type="html">The Hardware Lottery</title><link href="http://localhost:4000/posts/2023/the-hardware-lottery/" rel="alternate" type="text/html" title="The Hardware Lottery" /><published>2023-01-24T00:00:00+01:00</published><updated>2023-01-24T00:00:00+01:00</updated><id>http://localhost:4000/posts/2023/the-hardware-lottery</id><content type="html" xml:base="http://localhost:4000/posts/2023/the-hardware-lottery/"><![CDATA[<p>Sara Hooker, <a href="https://arxiv.org/abs/2009.06489">“The hardware lottery”</a>, Commun. ACM 64, 12, December 2021, pp. 58-65, https://doi.org/10.1145/3467017</p>

<h4 id="synopsis">Synopsis</h4>
<p>The term, Hardware Lottery, is used to define the unintentional prejudice observed historically towards certain research ideas in computer science that succeed, not because they were far superior to others but due to how well-suited they were for the available hardware and software of the time, often creating ‘noise’ to the interpretability of new research directions. The domain-specific era is even more prone to this, where the hardware landscape is getting even more fragmented. Figure 1 demonstrates this. Writing software for each system is expensive and even then chances are only those companies would succeed whose technologies can successfully be adopted to commercial applications. Specialised hardware can be replaced with the advent of newer technologies, therefore scalability and adoptability is critical to a hardware development infrastructure.</p>

<h4 id="strengths">Strengths</h4>
<p>The numerous examples from history from Edison’s Phonograph to modern GPUs is an eye opener and provides a broader perspective to think about the larger picture of computing hardware landscape. The presented solutions are agreed upon propositions in the research community. The emphasis on revisiting FPGAs and CGRAs for harmonising hardware development, developing better profiling tools and using AI for design space exploration is something I agree with. Secondly, just like hardware is being evolved to be highly parameterized, parameterized DSLs for reproducing results on different hardware is necessary (functional programming, and a higher abstraction level of application specification can help: e.g. Code Generating (Explainable) AI for hardware backends).</p>

<h4 id="weaknesses">Weaknesses</h4>
<p>The article highlights the issues that cost, limited availability, and the lack of standardisation in hardware, will make it difficult for researchers to replicate or reproduce results. One potential missing element in the article is the discussion that the difficulties in obtaining hardware resources also limits the number of researchers working on certain problems, and slowing down of progress in certain areas. It leads to a lack of diversity in the types of research being conducted, as researchers may be limited to working on problems that can be solved with the hardware they have available (not to mention, Gartner Hype Cycle). Additionally, an obstacle is technology not being available for researchers from underprivileged countries, institutions or backgrounds (IC production is Expensive!). Lastly, it could also be discussed that standardising a set of norms for developers (in academia and industry) would help mitigate the fragmented landscape, e.g. with the open-source hardware platform like RISC-V, and compiler infrastructure like LLVM/MLIR.</p>

<h4 id="thoughts">Thoughts</h4>
<p>Domain-Specific era didn’t dawn until Moore’s Law and Dennard Scaling stopped to apply. It can be worth investigating the next research idea (after-domain specific) and lay a path for its integration in future, which might not apply today for immediate adoption but can be simply available when needed [<span style="color:blue;">1</span>, <span style="color:blue;">2</span>]. This can be an expensive endeavour and may not succeed - “being too early is the same as being wrong” - so caution must be exercised. For academic research, some areas include, photonic accelerator, synaptic transistor, memristor array, new memory technology, neuromorphic etc. for hardware; Neurosymbolic AI, Formal Methods etc. for software. Secondly, while it is true presently that having specialised hardware can greatly accelerate the training of deep learning models, there are also other ways to address the issue of creating uniformity in the domain-specific landscape, such as algorithmic research to use general purpose hardware (not everything needs DL), using cloud computing resources, and creating cross-DSL(domain-specific language) compilers, DSE tools and open-source solutions. Lastly, one positive impact in the DS-era would be that small teams and independent researchers would be making breakthroughs with more limited resources through the use of creative solutions and open-source tools.</p>

<h4 id="takeaways">Takeaways</h4>
<p>Hardware development maintained its course ever since the 90s, however software developed fast (number of ML publications since 2005). This led to hardware being abstracted away completely by software. With increasing software complexity, hardware will be a key factor that would dictate the success for a research idea [<span style="color:blue;">3</span>]. Whereas for the hardware competing in the ‘bigger is better’ race, history tells us, “a deficiency in any one number of factors dooms an endeavour to failure.” A critical understanding of the hardware/software landscape, their compatibility and co-designability is therefore elemental.</p>
<ul>
  <li>Large new neural networks would need faster development time for corresponding accelerators, some architectures would need even more constrained design than scaling systolic arrays/vector architectures e.g. [<span style="color:blue;">4</span>, <span style="color:blue;">5</span>, <span style="color:blue;">6</span>] and [<span style="color:blue;">7</span>].</li>
  <li>Accelerating development time and cost is essential for hardware engineers. Ideas like [<span style="color:blue;">8</span>, <span style="color:blue;">9</span>] didn’t succeed because the cost of iteration was too high. For software, developers need to come up with creative solutions to adapt to the current norm of accelerators.</li>
  <li>Looking ahead is essential to progress, ideas respawn when the time is right e.g. the case of deep neural networks in software and [<span style="color:blue;">10</span>, <span style="color:blue;">11</span>] for corresponding hardware. Additionally, DNNs may not be the only way forward, at some point a new technology may spawn (e.g. something that better resembles the human brain) and we may have to redo everything. Scaling and Adaptability here needs more emphasis.</li>
  <li>From an economist’s perspective, the law of supply and demand is at play here. In one line, “Necessity is the mother of invention”.</li>
</ul>

<h4 id="favourite-bits">Favourite bits</h4>
<p>“Our own cognitive intelligence is both hardware and software [a domain-specific computer].”</p>

<p>“[accelerators] Happy families are all alike, unhappy families are unhappy in their own way.”</p>

<p>“[bigger is better race] An apt metaphor is that we may be trying to build a ladder to the moon.”</p>

<p>“Scientific progress occurs when there is a confluence of factors which allows scientists to overcome the ‘stickiness’ of the existing paradigm.”</p>

<p>“Registering what differs from our expectations, remains a key catalyst in driving new scientific discoveries.”</p>

<p>“[computer chip is] inscribing words on grains of sand.”</p>

<h4 id="suggested-reading">Suggested Reading</h4>
<p>Science in the age of selfies [<span style="color:blue;">12</span>].</p>

<h4 id="case-study-of-isa">Case study of ISA</h4>
<p>Krste Asanovic once said, ‘Don’t make your own ISAs.’ This is partly true in the sense that an incompatible ISA without existing software would never make it to upstream. We have observed the success of two proprietary ISAs so far, x86_64 and ARM32/64, asserting their dominance in desktop/server and mobile markets, respectively due to them being early and developing their own software ecosystem. Other ISAs of the time VAX, MIPS, SPARC etc became only moderately successful (and are now out of circulation). Why is it partly true? Because new systems, like Graphcore and Cerebras are bringing enough performance (in addition to marketing) to the table to compete in the HPC space.</p>

<h3 id="references">References</h3>
<div style="font-size:11pt">
[<span style="color:blue;">1</span>] Sutton, R. The bitter lesson, 2019. URL http://www.incompleteideas.net/IncIdeas/BitterLesson.html.<br />

[<span style="color:blue;">2</span>] Welling, M. Dowestill need modelsorjust more data and compute?, 2019. URL shorturl. at/qABIY.<br />

[<span style="color:blue;">3</span>] Barham, P. and Isard, M. Machine learning systems are stuck in a rut. In Proceedings of the Workshop on Hot Topics in Operating Systems, HotOS ’19, pp. 177–183, New York, NY, USA, 2019. Association for Computing Machinery. ISBN 9781450367271. doi: 10.1145/3317550.3321441. URL https://doi.org/10.1145/3317550.3321441.<br />

[<span style="color:blue;">4</span>] Hooker, S., Courville, A., Clark, G., Dauphin, Y., and Frome, A. What Do Compressed Deep Neural Networks Forget? arXiv e-prints, art. arXiv:1911.05248, November 2019.<br />

[<span style="color:blue;">5</span>] Gale, T., Elsen, E., and Hooker, S. The state of sparsity in deep neural networks, 2019.<br />

[<span style="color:blue;">6</span>] Evci, U., Gale, T., Menick, J., Castro, P. S., and Elsen, E. Rigging the Lottery: Making All Tickets Winners. arXiv e-prints, November 2019.<br />

[<span style="color:blue;">7</span>] Zhen, D., Yao, Z., Gholami, A., Mahoney, M., and Keutzer, K. Hawq: Hessian aware quantization of neural networks with mixedprecision, 10 2019.<br />

[<span style="color:blue;">8</span>] Kingsbury, B., Morgan, N., and Wawrzynek, J. Hipnet-1: A highly pipelined architecture for neural network training, 03 1998.<br />

[<span style="color:blue;">9</span>] Sackinger, E., Boser, B. E., Bromley, J., LeCun, Y., and Jackel, L. D. Application of the anna neural network chip to high-speed character recognition. IEEE Transactions on Neural Networks, 3(3):498–505, 1992.<br />

[<span style="color:blue;">10</span>] Hinton, G. E. and Anderson, J. A. Parallel Models of Associative Memory. L. Erlbaum Associates Inc., USA, 1989. ISBN 080580269X.<br />

[<span style="color:blue;">11</span>] Rumelhart, D. E., McClelland, J. L., and PDP Research Group, C. (eds.). Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations. MIT Press, Cambridge, MA, USA, 1986. ISBN 026268053X.<br />

[<span style="color:blue;">12</span>] Geman, Donald, and Stuart Geman. "Science in the age of selfies." Proceedings of the National Academy of Sciences 113.34 (2016): 9384-9387. <br />
</div>

<p><code class="language-plaintext highlighter-rouge">[This page is optimized for printing. Please consider saving paper by refraining from printing unless absolutely necessary.]</code></p>]]></content><author><name>Amitabh Yadav</name></author><category term="Digital Design and Simulation" /><summary type="html"><![CDATA[Sara Hooker, “The hardware lottery”, Commun. ACM 64, 12, December 2021, pp. 58-65, https://doi.org/10.1145/3467017]]></summary></entry></feed>