<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2021-12-29T19:56:05+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">C E R E V I E W</title><subtitle>CEREVIEW</subtitle><author><name>Amitabh Yadav</name></author><entry><title type="html">Book Review: The Emperor’s New Mind by Roger Penrose</title><link href="http://localhost:4000/Book-Review-The-Emperors-New-Mind/" rel="alternate" type="text/html" title="Book Review: The Emperor’s New Mind by Roger Penrose" /><published>2020-04-12T00:00:00+02:00</published><updated>2020-04-12T00:00:00+02:00</updated><id>http://localhost:4000/Book-Review-The-Emperors-New-Mind</id><content type="html" xml:base="http://localhost:4000/Book-Review-The-Emperors-New-Mind/">&lt;h2 id=&quot;review&quot;&gt;Review&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Will be updated when the book is finished (Estimated: April 30th, 2020).&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Please note that, this website also acts as my personal blog and an online notepad, where I prefer to take daily notes (using the Jekyll framework). Sp, the incomplete articles get updated in due course of time.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Chapter 1 presents a holistic view of the Turing Test. We dwell into the details to have the absolute test for an “indistinguishable from human” AI. The Turing Test is one such strong framework for testing an AI system where ‘clever methods’ used by the inquiring human can in practice present a hard situations for the AI at test. How relevant an AI’s behaviour is to act with ‘human flaws’ and how it behaves when posed with the ‘ridiculous’ questions are some of the hard tests within the Turing Test framework. We also talk about consiousness of AI and the concept of ‘pleasure’ and ‘pain’ for an AI. An AI can probably have a -100 to +100 scale for denoting pain and pleasure, respectively. Though what would happen in cases when human’s act impulsively without receiving the complete apprehension of pleasure or pain. The analogy used is that when we are about to touch as hot grill, the reation is impulsive without the need for quantizing pain. This chapter lays the foundation for the following chapters that’ll dwell deeper into conciousness, first from a computer science/mathematical point of view and later in the quantum mechanics framework.&lt;/p&gt;

&lt;p&gt;Chapter 2 goes into details of the Turing Machine as an implementation, and the need and significannce of having abstract concept of Turing Machine with the ‘infinite tape’ of I/O for performing computations. E.g. Euclid’s Algorithm for finding HCF is one of the oldest algorithms whose number of steps grows infinitely with the size of numbers. Euclid’s Algorithm was there even before Al Khwarizmi’s book on Algebra came from, that is the origin of the term, &lt;em&gt;Algorithm&lt;/em&gt;. Turing Machine is a abstract mathematical concept by Alan Turing in 1935-36 which originated from Hilbert’s posed problem called, &lt;em&gt;Entscheidungsproblem&lt;/em&gt; in 1928. The markings on the I/O tape of Turing machine can be considered in binary (for corresponding Denary (base-10) notation). Kurt Godel&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;currently reading.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;will be updated in due course of April 2020.&lt;/em&gt;&lt;/p&gt;</content><author><name>Amitabh Yadav</name></author><category term="Book Review" /><category term="Roger Penrose" /><category term="The Emperor&apos;s New Mind" /><category term="Book Review" /><summary type="html">Review Will be updated when the book is finished (Estimated: April 30th, 2020). Please note that, this website also acts as my personal blog and an online notepad, where I prefer to take daily notes (using the Jekyll framework). Sp, the incomplete articles get updated in due course of time. Summary Chapter 1 presents a holistic view of the Turing Test. We dwell into the details to have the absolute test for an “indistinguishable from human” AI. The Turing Test is one such strong framework for testing an AI system where ‘clever methods’ used by the inquiring human can in practice present a hard situations for the AI at test. How relevant an AI’s behaviour is to act with ‘human flaws’ and how it behaves when posed with the ‘ridiculous’ questions are some of the hard tests within the Turing Test framework. We also talk about consiousness of AI and the concept of ‘pleasure’ and ‘pain’ for an AI. An AI can probably have a -100 to +100 scale for denoting pain and pleasure, respectively. Though what would happen in cases when human’s act impulsively without receiving the complete apprehension of pleasure or pain. The analogy used is that when we are about to touch as hot grill, the reation is impulsive without the need for quantizing pain. This chapter lays the foundation for the following chapters that’ll dwell deeper into conciousness, first from a computer science/mathematical point of view and later in the quantum mechanics framework. Chapter 2 goes into details of the Turing Machine as an implementation, and the need and significannce of having abstract concept of Turing Machine with the ‘infinite tape’ of I/O for performing computations. E.g. Euclid’s Algorithm for finding HCF is one of the oldest algorithms whose number of steps grows infinitely with the size of numbers. Euclid’s Algorithm was there even before Al Khwarizmi’s book on Algebra came from, that is the origin of the term, Algorithm. Turing Machine is a abstract mathematical concept by Alan Turing in 1935-36 which originated from Hilbert’s posed problem called, Entscheidungsproblem in 1928. The markings on the I/O tape of Turing machine can be considered in binary (for corresponding Denary (base-10) notation). Kurt Godel currently reading. will be updated in due course of April 2020.</summary></entry><entry><title type="html">Processing in Memory: A workload driven perspective</title><link href="http://localhost:4000/articles/2022/processing-in-memory/" rel="alternate" type="text/html" title="Processing in Memory: A workload driven perspective" /><published>2020-04-07T00:00:00+02:00</published><updated>2020-04-07T00:00:00+02:00</updated><id>http://localhost:4000/articles/2022/processing-in-memory-a-workload-driven-perspective</id><content type="html" xml:base="http://localhost:4000/articles/2022/processing-in-memory/">&lt;p&gt;Performance gap between Memory (DRAM latencies) and Processor due to technology scaling is the motivation to investigate &lt;em&gt;Processing in Memory (PIM)&lt;/em&gt; architectures, also known as &lt;em&gt;Near Data Processing&lt;/em&gt;. Energy, Performance and Cost must be optimized. PIM tackles this by bringing computation to the data (and removing the data movement latencies). PIM is both: Completely new architectures and varying degree of architectural modifications in Memory Subsystems. This paper discusses the application of PIM in real-world applications (such as, Machine Learning, Data analytics, genome sequencing etc.), how to design the programming framework and the challenge of adoption of the new framework among the developer community.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Data moves from the Memory to the CPU via the &lt;em&gt;memory channel&lt;/em&gt; (a pin-limited off-chip Bus e.g. &lt;em&gt;double data-rate&lt;/em&gt; Memories aka &lt;em&gt;DDR&lt;/em&gt; use a 64-bit memory channel.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The CPU issues request to the &lt;em&gt;Memory Controller&lt;/em&gt;, which issues command across the memory channel to the DRAM.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The DRAM then reads the data and moves across the memory channel to the CPU (where the data has to travel through the memory hierarchy into the CPU’s register).&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Therefore, we need to rethink the computer architecture. PIM is one of such methods. The idea is almost 40 years old, but the technology was not mature enough to integrate a Memory with Processor elements. Technology such as 3D Stacked Memory (combining DRAM &lt;em&gt;Memory layers&lt;/em&gt; connected using through-layer &lt;em&gt;via&lt;/em&gt; along with a &lt;em&gt;logic layer&lt;/em&gt;), and more-computation friendly &lt;em&gt;resistive memory technologies&lt;/em&gt;, makes it possible to embed general-purpose computation directly within the memory.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Challenges:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;Identification of application properties that can benefit from PIM architectures.&lt;/li&gt;
  &lt;li&gt;Making the architecture heterogeneous requires understanding of: a) architectural constraints (area, energy limitations along with the logic that is implementable within the memory), and b) application properties, such as memory access patterns and shared-data across different functions.&lt;/li&gt;
  &lt;li&gt;Therefore we need to understand the partition between PIM logic and CPU driven logic, establish the interfaces and mechanism for programming (while trying to stay close to the conventional programming model).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;overview-of-pim&quot;&gt;Overview of PIM&lt;/h2&gt;

&lt;p&gt;Quantization Effectiveness:&lt;/p&gt;

&lt;h2 id=&quot;opportunities-in-pim-applications&quot;&gt;Opportunities in PIM applications&lt;/h2&gt;

&lt;h2 id=&quot;key-issues-in-programming-pim-architectures&quot;&gt;Key Issues in Programming PIM architectures&lt;/h2&gt;

&lt;h2 id=&quot;related-work&quot;&gt;Related Work&lt;/h2&gt;

&lt;h2 id=&quot;future-challenges&quot;&gt;Future Challenges&lt;/h2&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;lessons-learnt&quot;&gt;Lessons Learnt&lt;/h2&gt;

&lt;h2 id=&quot;pros-and-cons-of-the-paper&quot;&gt;Pros and Cons of the Paper&lt;/h2&gt;

&lt;h2 id=&quot;improvement-ideas&quot;&gt;Improvement Ideas&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;strong&gt;Memory Bottleneck:&lt;/strong&gt; Moving large amount of data for High-Performance and Data-Intense applications causes the bottleneck on energy and performance of the processor. The limited size of memory channel limits the number of access requests that can be issued in parallel, and the Random access patterns often leads to inefficient caching. The total cost of computation (in terms of performance and energy) is dominated by the cost of data movement. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Amitabh Yadav</name></author><category term="Computer Architecture" /><category term="Memory" /><category term="computer architecture" /><category term="in-memory computing" /><category term="3d ram" /><category term="memristor" /><category term="processing in memory" /><category term="pim architectures" /><summary type="html">Performance gap between Memory (DRAM latencies) and Processor due to technology scaling is the motivation to investigate Processing in Memory (PIM) architectures, also known as Near Data Processing. Energy, Performance and Cost must be optimized. PIM tackles this by bringing computation to the data (and removing the data movement latencies). PIM is both: Completely new architectures and varying degree of architectural modifications in Memory Subsystems. This paper discusses the application of PIM in real-world applications (such as, Machine Learning, Data analytics, genome sequencing etc.), how to design the programming framework and the challenge of adoption of the new framework among the developer community. Introduction Data moves from the Memory to the CPU via the memory channel (a pin-limited off-chip Bus e.g. double data-rate Memories aka DDR use a 64-bit memory channel.) The CPU issues request to the Memory Controller, which issues command across the memory channel to the DRAM. The DRAM then reads the data and moves across the memory channel to the CPU (where the data has to travel through the memory hierarchy into the CPU’s register).1 Therefore, we need to rethink the computer architecture. PIM is one of such methods. The idea is almost 40 years old, but the technology was not mature enough to integrate a Memory with Processor elements. Technology such as 3D Stacked Memory (combining DRAM Memory layers connected using through-layer via along with a logic layer), and more-computation friendly resistive memory technologies, makes it possible to embed general-purpose computation directly within the memory. Challenges: Identification of application properties that can benefit from PIM architectures. Making the architecture heterogeneous requires understanding of: a) architectural constraints (area, energy limitations along with the logic that is implementable within the memory), and b) application properties, such as memory access patterns and shared-data across different functions. Therefore we need to understand the partition between PIM logic and CPU driven logic, establish the interfaces and mechanism for programming (while trying to stay close to the conventional programming model). Overview of PIM Quantization Effectiveness: Opportunities in PIM applications Key Issues in Programming PIM architectures Related Work Future Challenges Conclusion Lessons Learnt Pros and Cons of the Paper Improvement Ideas Memory Bottleneck: Moving large amount of data for High-Performance and Data-Intense applications causes the bottleneck on energy and performance of the processor. The limited size of memory channel limits the number of access requests that can be issued in parallel, and the Random access patterns often leads to inefficient caching. The total cost of computation (in terms of performance and energy) is dominated by the cost of data movement. &amp;#8617;</summary></entry></feed>